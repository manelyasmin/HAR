# -*- coding: utf-8 -*-
"""Copie de Copie de HACKANONS COLAB 25GB COPIE31MAI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12Nw12DOIV_n9Xoj3pfqB4qkmmVnUPhYv

#VERSION OF 16/06/2021 NEW DATA WITH 9 FRAMES AND RAM OF 35G

**connect to drive**
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
#load train and test data 
with open('/content/drive/MyDrive/y_train.npy', 'rb') as f :
  y_train = np.load(f)
with open('/content/drive/MyDrive/X_test.npy', 'rb') as f :
  X_test = np.load(f)
with open('/content/drive/MyDrive/y_test.npy', 'rb') as f :
  y_test = np.load(f)
with open('/content/drive/MyDrive/X_train.npy', 'rb') as f :
  X_train = np.load(f)

import matplotlib.pyplot as plt
import numpy as np
from tensorflow import keras
from keras.utils import np_utils
from sklearn.model_selection import train_test_split
from keras import regularizers
from keras import Sequential
from keras.layers import AveragePooling3D,Dense,ReLU,LeakyReLU,GlobalAveragePooling3D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation
model = Sequential()
model.add(Conv3D(16, kernel_size=(3, 3,3),strides=(1,2,2),input_shape=(9,120,108,3)))
model.add(ReLU())
model.add(Dropout(0.15))
model.add(Conv3D(32, kernel_size=(3, 3,3),strides=(2,2,2)))
model.add(ReLU())
model.add(MaxPooling3D(pool_size=(1, 2,2))) 
model.add(Dropout(0.15))
model.add(Conv3D(64, kernel_size=(1, 3,3),strides=(1,2,2)))
model.add(ReLU())
model.add(Dropout(0.25))
model.add(Conv3D(128, kernel_size=(1, 3,3),strides=(1,2,2)))
model.add(ReLU())  
model.add(MaxPooling3D(pool_size=(1, 1,1))) 

model.add(Flatten()) 
model.add(Dense(256, kernel_regularizer=regularizers.l1(0.001)))
model.add(ReLU())
model.add(Dropout(0.25))
model.add(Dense(256, kernel_regularizer=regularizers.l1(0.001)))
model.add(ReLU())
model.add(Dense(6, activation='softmax'))
model.summary()

optimizer = keras.optimizers.Adam(learning_rate=0.00001,beta_1=0.9,beta_2=0.999)
  model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])
  history = model.fit(X_train,y_train,batch_size=6,epochs=100,verbose=1,validation_split=0.2)

model.save("/content/drive/MyDrive/model9frame3epochs.h5")

def plot_learning_curve(history, epochs):
  #Plot training and validation accuracy values:
  epoch_range = range(1, epochs+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.xlabel('Epochs')
  plt.ylabel('Acuuracy')
  plt.title('Accuracy curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  plt.savefig('/content/drive/My Drive/Accuracymodel9frame3epochs.png')

  #Plot training and validation loss values :
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.axis([0,100, 0,15])
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('Loss curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  plt.savefig('/content/drive/My Drive/Lossmodel9frame3epochs.png')
EPOCHS=100
plot_learning_curve(history, EPOCHS)

model.evaluate(X_test,y_test)

print(X_test.shape)

import matplotlib.pyplot as plt
  import numpy as np
  from tensorflow import keras
  from keras.utils import np_utils
  from sklearn.model_selection import train_test_split
  from keras import regularizers
  from keras import Sequential
  from keras.layers import AveragePooling3D,Dense,ReLU,LeakyReLU,GlobalAveragePooling3D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation

  model = Sequential()
  model.add(Conv3D(16, kernel_size=(3, 3,3),strides=(1,2,2),input_shape=(9,120,108,3)))
  model.add(ReLU())
  model.add(Dropout(0.15))
  model.add(Conv3D(32, kernel_size=(3, 3,3),strides=(2,2,2)))
  model.add(ReLU())
  model.add(MaxPooling3D(pool_size=(1, 2,2))) 
  model.add(Dropout(0.15))
  model.add(Conv3D(64, kernel_size=(1, 3,3),strides=(1,2,2)))
  model.add(ReLU())
  model.add(Dropout(0.25))
  model.add(Conv3D(128, kernel_size=(1, 3,3),strides=(1,2,2)))
  model.add(ReLU())  
  model.add(MaxPooling3D(pool_size=(1, 1,1))) 

  model.add(Flatten()) 
  #, bias_regularizer=regularizers.l1(0.01)
  model.add(Dense(256, kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU())
  model.add(Dropout(0.25))
  model.add(Dense(256, kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU())
  model.add(Dropout(0.25))
  model.add(Dense(6, activation='softmax'))
  model.summary()

optimizer = keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.999)
  model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])
  history = model.fit(X_train,y_train,batch_size=6,epochs=100,verbose=1,validation_split=0.2)

import matplotlib.pyplot as plt
import numpy as np
from tensorflow import keras
from keras.utils import np_utils
from sklearn.model_selection import train_test_split
from keras import regularizers
from keras import Sequential
from keras.layers import AveragePooling3D,Dense,ReLU,LeakyReLU,GlobalAveragePooling3D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation

model = Sequential()
model.add(Conv3D(16, kernel_size=(3, 3,3),strides=(1,2,2),input_shape=(9,120,108,3)))
model.add(ReLU())
model.add(Dropout(0.15))
model.add(Conv3D(32, kernel_size=(3, 3,3),strides=(2,2,2)))
model.add(ReLU())
model.add(MaxPooling3D(pool_size=(1, 2,2))) 
model.add(Dropout(0.15))
model.add(Conv3D(64, kernel_size=(1, 3,3),strides=(1,2,2)))
model.add(ReLU())
model.add(Dropout(0.25))
model.add(Conv3D(128, kernel_size=(1, 3,3),strides=(1,2,2)))
model.add(ReLU())  
model.add(MaxPooling3D(pool_size=(1, 1,1))) 

model.add(Flatten()) 
#, bias_regularizer=regularizers.l1(0.01)
model.add(Dense(256, kernel_regularizer=regularizers.l2(0.002)))
model.add(ReLU())
model.add(Dropout(0.25))
model.add(Dense(256, kernel_regularizer=regularizers.l2(0.002)))
model.add(ReLU())
model.add(Dense(6, activation='softmax'))
model.summary()

optimizer = keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.999)
  model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])
  history = model.fit(X_train,y_train,batch_size=9,epochs=100,verbose=1,validation_split=0.2)

import matplotlib.pyplot as plt
# %matplotlib inline

  from tensorflow import keras
  from keras.utils import np_utils
  from sklearn.model_selection import train_test_split

  from keras import regularizers
  from keras import Sequential
  from keras.layers import Dense,ReLU,LeakyReLU,GlobalAveragePooling3D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation


  model = Sequential()
  model.add(Conv3D(16, kernel_size=(3, 3,3),strides=(1,2,2),input_shape=(7,120,108,3)))
  model.add(ReLU())
  model.add(Dropout(0.15))
  model.add(Conv3D(32, kernel_size=(3, 3,3),strides=(2,2,2)))
  model.add(ReLU())
  model.add(MaxPooling3D(pool_size=(1, 2,2))) 
  model.add(Dropout(0.15))
  model.add(Conv3D(64, kernel_size=(1, 3,3),strides=(1,2,2)))
  model.add(ReLU())
  model.add(Dropout(0.25))
  model.add(Conv3D(128, kernel_size=(1, 3,3),strides=(1,2,2)))
  model.add(ReLU())  
  model.add(MaxPooling3D(pool_size=(1, 1,1))) 

  model.add(Flatten()) 
  model.add(Dense(256, kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU())
  model.add(Dropout(0.25))
  model.add(Dense(256, kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU())
  model.add(Dense(6, activation='softmax'))
  model.summary()

optimizer = keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.5,beta_2=0.999)
model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])
EPOCHS=50 
history = model.fit(X_train,y_train,batch_size=4,epochs=EPOCHS,verbose=1,validation_split=0.2)

import numpy as np 
        import matplotlib.pyplot as plt
        from tensorflow import keras
        from keras.utils import np_utils
        from sklearn.model_selection import train_test_split
        from keras import regularizers
        from keras import Sequential
        from keras.layers import Conv2D,MaxPooling2D, LSTM,TimeDistributed,Dense,ReLU,LeakyReLU,GlobalAveragePooling3D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation
        model = Sequential()
        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),
                                  input_shape=(7,120,108,3)))
        model.add(BatchNormalization())
        model.add(TimeDistributed(MaxPooling2D((2, 2))))
        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))
        model.add(BatchNormalization())
        model.add(TimeDistributed(MaxPooling2D((2, 2))))
        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))
        model.add(BatchNormalization())
        model.add(TimeDistributed(MaxPooling2D((2, 2))))
        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))
        model.add(BatchNormalization())
        
        model.add(TimeDistributed(MaxPooling2D((2, 2))))
        model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))
        model.add(BatchNormalization())
        model.add(TimeDistributed(MaxPooling2D((2, 2))))
        model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))
        model.add(BatchNormalization())
        model.add(TimeDistributed(MaxPooling2D((2, 2))))
        
        model.add(TimeDistributed(Flatten()))
        model.add(LSTM(128))
        #model.add(BatchNormalization())
        model.add(Dropout(0.25))
        model.add(Dense(128,activation='relu'))
        #model.add(BatchNormalization())
        #model.add(Dropout(0.25))
        model.add(Dense(6, activation='softmax'))
        model.summary()

optimizer = keras.optimizers.Adam(learning_rate=0.0001)
model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])
EPOCHS=20 
#sparse_categorical_crossentropy 
history = model.fit(X_train,y_train,batch_size=7,epochs=EPOCHS,verbose=1,validation_split=0.2)

def plot_learning_curve(history, epochs):
  #Plot training and validation accuracy values:
  epoch_range = range(1, epochs+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.xlabel('Epochs')
  plt.ylabel('Acuuracy')
  plt.title('Accuracy curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Accuracy2.png')

  #Plot training and validation loss values :
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.axis([0,20, 0,2])
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('Loss curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Loss2.png')
EPOCHS=20
plot_learning_curve(history, EPOCHS)

model.evaluate(X_test,y_test)

print(X_test.shape)

from keras.applications import mobilenet
from keras.layers import GRU 
        
import numpy as np 
import matplotlib.pyplot as plt
from tensorflow import keras
from keras.utils import np_utils
from sklearn.model_selection import train_test_split
from keras import regularizers
from keras import Sequential
from keras.layers import Bidirectional, Conv2D,MaxPooling2D, LSTM,TimeDistributed,Dense,ReLU,LeakyReLU,GlobalAveragePooling3D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation

mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)
 
class RNNCNN_TL2():
    
    def define_model(self,gru_cells=64,dense_neurons=64,dropout=0.7):
        
        model = Sequential()
        model.add(TimeDistributed(mobilenet_transfer,input_shape=(7,120,108,3)))
 
        
        model.add(TimeDistributed(BatchNormalization()))
        model.add(TimeDistributed(MaxPooling2D((2, 2))))
        model.add(TimeDistributed(Flatten()))
        #model.add(Flatten())
        model.add(Bidirectional(LSTM(128)))
        model.add(ReLU())
        #model.add(LSTM(gru_cells))
        model.add(Dropout(dropout))
        
        model.add(Dense(128,activation='relu'))
        model.add(Dropout(dropout))
        
        model.add(Dense(6, activation='softmax'))
        model.summary()
        #optimiser = optimizers.Adam()
        #model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])
         
        return model


# In[ ]:


rnn_cnn_tl2=RNNCNN_TL2()
model=rnn_cnn_tl2.define_model()
#rnn_cnn_tl2.initialize_path(project_folder)
#rnn_cnn_tl2.initialize_image_properties(image_height=120,image_width=108)
#rnn_cnn_tl2.initialize_hyperparams(frames_to_sample=16,batch_size=7,num_epochs=7)
#rnn_cnn_tl2_model=rnn_cnn_tl2.define_model(gru_cells=128,dense_neurons=128,dropout=0.25)
 


#print("Total Params:", rnn_cnn_tl2_model.count_params())
#history_model17=rnn_cnn_tl2.train_model(rnn_cnn_tl2_model,augment_data=True)

from keras.applications import mobilenet
from keras.layers import GRU 
        
import numpy as np 
import matplotlib.pyplot as plt
from tensorflow import keras
from keras.utils import np_utils
from sklearn.model_selection import train_test_split
from keras import regularizers
from keras import Sequential
from keras.layers import Bidirectional, Conv2D,MaxPooling2D, LSTM,TimeDistributed,Dense,ReLU,LeakyReLU,GlobalAveragePooling3D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation
model = Sequential()
model.add(Conv3D(16, (3, 3, 3), padding='same',input_shape=(7,120,108,3)))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling3D(pool_size=(2, 2, 2)))

model.add(Conv3D(32, (3, 3, 3), padding='same'))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling3D(pool_size=(2, 2, 2)))

model.add(Conv3D(64, (2, 2, 2), padding='same'))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling3D(pool_size=(1, 2, 2)))

model.add(Conv3D(128, (2, 2, 2), padding='same'))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling3D(pool_size=(1, 2, 2)))

model.add(Flatten())
model.add(Dense(64,activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(Dense(64,activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))
model.add(Dense(6,activation='softmax'))
model.summary()

optimizer = keras.optimizers.Adam(learning_rate=0.00001)
model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])
EPOCHS=50 
#sparse_categorical_crossentropy 
history = model.fit(X_train,y_train,batch_size=4,epochs=EPOCHS,verbose=1,validation_split=0.2)

import numpy as np 

  import matplotlib.pyplot as plt
  
  from tensorflow import keras
  from keras.utils import np_utils
  from sklearn.model_selection import train_test_split

  from keras import regularizers
  from keras import Sequential
  from keras.layers import LSTM,TimeDistributed,Dense,ReLU,LeakyReLU,GlobalAveragePooling3D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation


  model = Sequential()
  model.add(Conv3D(16, kernel_size=(3, 3,3),strides=(1,2,2),input_shape=(7,120,108,3)))
  model.add(ReLU()) 
  model.add(Dropout(0.15)) 
  model.add(Conv3D(32, kernel_size=(3, 3,3),strides=(2,2,2)))
  model.add(ReLU()) 
  
  model.add(MaxPooling3D(pool_size=(1, 2,2))) 
  #model.add(Dropout(0.15))
  
  model.add(Conv3D(64, kernel_size=(1, 3,3),strides=(1,2,2)))
  model.add(ReLU()) 
  model.add(Dropout(0.25))
  #model.add(BatchNormalization())
  model.add(Conv3D(128, kernel_size=(1, 3,3),strides=(1,2,2)))
  model.add(ReLU()) 
  model.add(MaxPooling3D(pool_size=(1, 1,1))) 
  model.add(Flatten())
  #model.add(TimeDistributed(Flatten())) 
  model.add(Dense(256, kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU()) 
  model.add(Dropout(0.25))
  model.add(Dense(128, kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU()) 
  model.add(Dropout(0.25))
  model.add(Dense(6, activation='softmax'))
  model.summary()

optimizer = keras.optimizers.Adam(learning_rate=0.0001)
model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])
EPOCHS=50 
#sparse_categorical_crossentropy 
history = model.fit(X_train,y_train,batch_size=4,epochs=EPOCHS,verbose=1,validation_split=0.2)

def plot_learning_curve(history, epochs):
  #Plot training and validation accuracy values:
  epoch_range = range(1, epochs+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.xlabel('Epochs')
  plt.ylabel('Acuuracy')
  plt.title('Accuracy curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Accuracy2.png')

  #Plot training and validation loss values :
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.axis([0,50, 0,2])
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('Loss curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Loss2.png')
EPOCHS=50
plot_learning_curve(history, EPOCHS)

model.evaluate(X_test,y_test)

print(X_test.shape)

import numpy as np 

  import matplotlib.pyplot as plt
  
  from tensorflow import keras
  from keras.utils import np_utils
  from sklearn.model_selection import train_test_split

  from keras import regularizers
  from keras import Sequential
  from keras.layers import LSTM,TimeDistributed,Dense,ReLU,LeakyReLU,GlobalAveragePooling3D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation


  model = Sequential()
  model.add(Conv3D(16, kernel_size=(3, 3,3),input_shape=(7,120,108,3)))
  model.add(ReLU()) 
  model.add(BatchNormalization())
  model.add(MaxPooling3D(pool_size=(1, 2,2))) 

  model.add(Conv3D(32, kernel_size=(3, 3,3)))
  model.add(ReLU()) 
  model.add(BatchNormalization())
  model.add(MaxPooling3D(pool_size=(1, 2,2))) 
   

  model.add(Conv3D(64, kernel_size=(2, 2,2)))
  model.add(ReLU()) 
  model.add(BatchNormalization())
  model.add(MaxPooling3D(pool_size=(2, 2,2))) 

  model.add(Conv3D(128, kernel_size=(2, 2,2)))
  model.add(ReLU()) 
  model.add(BatchNormalization())
  model.add(MaxPooling3D(pool_size=(2, 2,2)))  
  model.add(Flatten())
  #model.add(TimeDistributed(Flatten())) 
  model.add(Dense(256, kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU())
  model.add(BatchNormalization())
  model.add(Dropout(0.25))
  model.add(Dense(128, kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU())
  model.add(BatchNormalization())
  model.add(Dropout(0.25))
  model.add(Dense(6, activation='softmax'))
  model.summary()

optimizer = keras.optimizers.Adam(learning_rate=0.0001)
model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])
EPOCHS=50 
#sparse_categorical_crossentropy 
history = model.fit(X_train,y_train,batch_size=4,epochs=EPOCHS,verbose=1,validation_split=0.2)





with open('/content/drive/MyDrive/dataset_har_hit/pushing.npy', 'rb') as f :
    hit_arr = np.load(f)    
    hit_arr= hit_arr[:870,:,:,:,:]

with open('/content/drive/MyDrive/dataset_har_hit/normal.npy', 'rb') as f :
    normal_arr = np.load(f)    
    normal_arr= normal_arr[:870,:,:,:,:]

print("kicking ",kicking_arr.shape)
print("pushing ",hit_arr.shape)
print("vomiting ",vomiting_arr.shape)
print("falling ",falling_arr.shape)
print("wieldknife ",wieldknife_arr.shape)
print("noOne ",noOne_arr.shape)

import numpy as np 
X_data = np.concatenate((kicking_arr,hit_arr,wieldknife_arr,vomiting_arr,falling_arr,noOne_arr))
#kicking,pushing,vomiting,falling,hit,noone
print(X_data.shape)

with open('X_data.npy', 'wb') as f:

    np.save(f,X_data)

import numpy as np 
with open('/content/X_data.npy', 'rb') as f :
  Xdata = np.load(f)

X_labels=np.ones((len(X_data),),dtype = int)
X_labels[0:869]= 0
X_labels[870:1739]= 1
X_labels[1740:2609] = 2
X_labels[2610:3479] = 3
X_labels[3480:4349] = 4
X_labels[4350:5219] = 5

import numpy as np

import matplotlib.pyplot as plt
# %matplotlib inline

from tensorflow import keras
from keras.utils import np_utils
from sklearn.model_selection import train_test_split

from keras import regularizers
from keras import Sequential
from keras.layers import Dense, Conv3D, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation

Ydata = np_utils.to_categorical(X_labels)

X_train, X_test, y_train, y_test = train_test_split(X_data, Ydata, test_size=0.2, random_state=42)

print("X_train shape :", X_train.shape)
print("X_test shape :", X_test.shape)
print("y_train shape :" , y_train.shape)
print("y_test shape :", y_test.shape)

with open('X_train.npy', 'wb') as f:

    np.save(f,X_train)

with open('y_test.npy', 'wb') as f:

    np.save(f,y_test)

with open('X_test.npy', 'wb') as f:

    np.save(f,X_test)

with open('y_train.npy', 'wb') as f:

    np.save(f,y_train)

!cp "/content/y_train.npy" -r "/content/drive/MyDrive/"

import numpy as np 
  import matplotlib.pyplot as plt
  from tensorflow import keras
  from keras.utils import np_utils
  from sklearn.model_selection import train_test_split

  from keras import regularizers
  from keras import Sequential
  from keras.layers import TimeDistributed,LSTM,MaxPooling2D,Dense,ReLU,LeakyReLU,GlobalAveragePooling3D,ConvLSTM2D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation
  def define_model():
   model = Sequential()
   model.add(ConvLSTM2D(filters = 16, kernel_size = (3,3),strides= (2,2), return_sequences = True,
                       data_format = "channels_last", input_shape = (7, 120, 108, 3)))
   #model.add(MaxPooling3D(pool_size=(2, 2,2), padding='same', data_format='channels_last'))
   model.add(ReLU())
   model.add(ConvLSTM2D(filters = 32, kernel_size = (3,3),strides= (2,2) ))
   model.add(ReLU())
   model.add(MaxPooling2D(pool_size=( 3,3)))
   #model.add(ConvLSTM2D(filters = 64, kernel_size = (2,1),strides= (1,1)))

   model.add(TimeDistributed(Flatten()))
    
   model.add(LSTM(256, kernel_regularizer=regularizers.l1(0.001)))
   model.add(ReLU())
   model.add(Dropout(0.25))
   
   model.add(Dense(6, activation = "softmax"))

   return model

model = define_model()
model.summary()

import numpy as np 
  import matplotlib.pyplot as plt
  from tensorflow import keras
  from keras.utils import np_utils
  from sklearn.model_selection import train_test_split

  from keras import regularizers
  from keras import Sequential
  from keras.layers import Dense,ReLU,LeakyReLU,GlobalAveragePooling3D,ConvLSTM2D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation
def define_model():
  model = Sequential()
  model.add(ConvLSTM2D(filters = 8, kernel_size = (3,3),strides= (2,2), return_sequences = True, 
                       data_format = "channels_last", input_shape = (7, 120, 108, 3)))
  model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same', data_format='channels_last'))
  model.add(ConvLSTM2D(filters = 16, kernel_size = (3,3),strides= (2,2), return_sequences = True, 
                       data_format = "channels_last", input_shape = (7, 120, 108, 3)))
  model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same', data_format='channels_last'))

  model.add(ConvLSTM2D(filters = 32, kernel_size = (3,3),strides= (2,2), return_sequences = True, 
                       data_format = "channels_last", input_shape = (7, 120, 108, 3)))
  model.add(MaxPooling3D(pool_size=(2, 3, 3), padding='same', data_format='channels_last'))
   
  model.add(Flatten())
  model.add(Dropout(0.5))
  model.add(Dense(6, activation = "softmax"))

  return model

model = define_model()
model.summary()

# Commented out IPython magic to ensure Python compatibility.
from scipy.stats import mode
import numpy as np
#from mnist import MNIST
from time import time
import pandas as pd
import os
import matplotlib.pyplot as matplot
import matplotlib
# %matplotlib inline

import random
matplot.rcdefaults()
from IPython.display import display, HTML
from itertools import chain
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
import seaborn as sb
from sklearn.model_selection import ParameterGrid
from sklearn.svm import SVC, LinearSVC
import warnings
from sklearn.metrics import confusion_matrix,classification_report
y_pred=model.predict(X_test) 
y_pred=np.argmax(y_pred, axis=1)
y_test=np.argmax(y_test, axis=1)
cm = confusion_matrix(y_test, y_pred)
print(cm)
print(classification_report(y_test,y_pred))
matplot.subplots(figsize=(10, 6))
sb.heatmap(cm, annot = True, fmt = 'g')
matplot.xlabel("Predicted")
matplot.ylabel("Actual")
matplot.title("Confusion Matrix")
matplot.show()

import numpy as np


def plot_confusion_matrix(cm,target_names,title='Confusion matrix',cmap=None,normalize=True):
   
    import matplotlib.pyplot as plt
    import numpy as np
    import itertools

    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names, rotation=45)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")


    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))
    plt.show()

plot_confusion_matrix(cm,[0,1,2,3,4,5],title='Confusion matrix',cmap=None,normalize=True)
#kicking,pushing,vomiting,falling,hit,noone



import numpy as np 
  import matplotlib.pyplot as plt
  from tensorflow import keras
  from keras.utils import np_utils
  from sklearn.model_selection import train_test_split

  from keras import regularizers
  from keras import Sequential
  from keras.layers import TimeDistributed,LSTM,MaxPooling2D,Dense,ReLU,LeakyReLU,GlobalAveragePooling3D,ConvLSTM2D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation
  def define_model():
   model = Sequential()
   model.add(ConvLSTM2D(filters = 16, kernel_size = (3,3),strides= (2,2), return_sequences = True, 
                       data_format = "channels_last", input_shape = (7, 120, 108, 3)))
   #model.add(MaxPooling3D(pool_size=(2, 2,2), padding='same', data_format='channels_last'))
   model.add(ConvLSTM2D(filters = 32, kernel_size = (2,2),strides= (2,2)))
   model.add(MaxPooling2D(pool_size=( 2,2)))

   model.add((Flatten()))
   model.add(Dense(512, activation='relu' ,kernel_regularizer=regularizers.l1(0.001)))
   model.add(Dropout(0.25))
   model.add(Dense(256, activation='relu' ,kernel_regularizer=regularizers.l1(0.001)))
   model.add(Dropout(0.25))
   model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l1(0.001)))
   model.add(Dense(6, activation = "softmax"))

   return model

model = define_model()
model.summary()

def plot_learning_curve(history, epochs):
  #Plot training and validation accuracy values:
  epoch_range = range(1, epochs+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.xlabel('Epochs')
  plt.ylabel('Acuuracy')
  plt.title('Accuracy curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Accuracy2.png')

  #Plot training and validation loss values :
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.axis([0,50, 0,4])
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('Loss curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Loss2.png')
EPOCHS=50
plot_learning_curve(history, EPOCHS)

model.evaluate(X_test,y_test)

print(X_test.shape)

from tensorflow import keras
model = keras.models.load_model('/content/drive/MyDrive/goodlossaccuracybadgraph.h5')

path='/content/drive/MyDrive/listeTest'
activite='vomi11'
frame_extraction(path,activite)
import numpy as np 
with open("/content/vomi11.npy","rb") as f:
  push=np.load(f)
print(push.shape)

with open("/content/drive/MyDrive/dataset_har_hit/noOne.npy","rb") as f:
  push=np.load(f)
print(push.shape)

import matplotlib.pyplot as plt
img4=push[123,4,:,:,:]
plt.imshow(img4)

import numpy as np 
listofFrames=[]
#3 4 5 7
img=push[13,0,:,:,:]
listofFrames.append(img)
img1=push[13,1,:,:,:]
listofFrames.append(img1)
img2=push[13,2,:,:,:]
listofFrames.append(img2)
img3=push[13,3,:,:,:]
listofFrames.append(img3)
img4=push[13,4,:,:,:]
listofFrames.append(img4)
img5=push[13,5,:,:,:]
listofFrames.append(img5)
img6=push[13,6,:,:,:]
listofFrames.append(img6)
import numpy as np 
image = np.expand_dims(listofFrames, axis=0)
prediction = model.predict(image)
import numpy as np 
image = np.expand_dims(listofFrames, axis=0)
prediction = model.predict(image)
print("\nResults:")
#X_data = np.concatenate((kicking_arr,pushing_arr,vomiting_arr,falling_arr,wieldknife_arr,noOne_arr))

print("Action: kicking                --- Score: %.2f %%" % (prediction[0][0]*100))
print("Action: pushing                --- Score: %.2f %%" % (prediction[0][1]*100))
print("Action: vomiting                --- Score: %.2f %%" % (prediction[0][2]*100))
print("Action: falling                  --- Score: %.2f %%" % (prediction[0][3]*100))
print("Action: wieldknife                --- Score: %.2f %%" % (prediction[0][4]*100))
print("Action: noOne                      --- Score: %.2f %%" % (prediction[0][5]*100))
print("----------------------------------------------------------\n")
##kicking,pushing,vomiting,falling,hit,noone

import matplotlib.pyplot as plt
img4=push[13,3,:,:,:]
plt.imshow(img4)

import numpy as np 
  import matplotlib.pyplot as plt
  from tensorflow import keras
  from keras.utils import np_utils
  from sklearn.model_selection import train_test_split

  from keras import regularizers
  from keras import Sequential
  from keras.layers import Dense,ReLU,LeakyReLU,GlobalAveragePooling3D,ConvLSTM2D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation


  model = Sequential()
  model.add(Conv3D(16, kernel_size=(3, 3,3),strides=(1,2,2),input_shape=(7,120,108,3)))
  model.add(ReLU())
  model.add(Conv3D(32, kernel_size=(3, 3,3),strides=(1,2,2)))
  model.add(ReLU())
  model.add(MaxPooling3D(pool_size=(1, 2,2))) 
  model.add(Dropout(0.5))
  model.add(Conv3D(64, kernel_size=(1, 3,3),strides=(1,2,2)))
  model.add(ReLU())  
  model.add(Conv3D(128, kernel_size=(1, 3,3),strides=(1,2,2)))
  model.add(ReLU())  
   
  model.add(Flatten()) 
  model.add(Dense(256, kernel_regularizer=regularizers.l1_l2(0.001)))
  model.add(Dropout(0.5))
  model.add(ReLU())  
  model.add(Dense(128, kernel_regularizer=regularizers.l1_l2(0.001)))
  model.add(ReLU()) 
  model.add(Dense(6, activation='softmax'))
  model.summary()

def plot_learning_curve(history, epochs):
  #Plot training and validation accuracy values:
  epoch_range = range(1, epochs+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.xlabel('Epochs')
  plt.ylabel('Acuuracy')
  plt.title('Accuracy curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Accuracy2.png')

  #Plot training and validation loss values :
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.axis([0,50, 0,2])
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('Loss curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Loss2.png')
EPOCHS=50
plot_learning_curve(history, EPOCHS)

model.evaluate(X_test,y_test)

print(X_test.shape)

model.save("with.h5")

import numpy as np 
  import matplotlib.pyplot as plt
  from tensorflow import keras
  from keras.utils import np_utils
  from sklearn.model_selection import train_test_split

  from keras import regularizers
  from keras import Sequential
  from keras.layers import Dense,ReLU,LeakyReLU,GlobalAveragePooling3D,ConvLSTM2D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation

def define_model():
  model = Sequential()
  model.add(ConvLSTM2D(filters = 8, kernel_size = (3,3),strides= (2,2), return_sequences = True, 
                       data_format = "channels_last", input_shape = (7, 120, 108, 3)))
  model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same', data_format='channels_last'))
  model.add(ConvLSTM2D(filters = 16, kernel_size = (3,3),strides= (2,2), return_sequences = True, 
                       data_format = "channels_last", input_shape = (7, 120, 108, 3)))
  model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same', data_format='channels_last'))

  model.add(ConvLSTM2D(filters = 32, kernel_size = (3,3),strides= (2,2), return_sequences = True, 
                       data_format = "channels_last", input_shape = (7, 120, 108, 3)))
  model.add(MaxPooling3D(pool_size=(2, 3, 3), padding='same', data_format='channels_last'))
   
  model.add(Flatten())
  model.add(Dropout(0.5))
  model.add(Dense(6, activation = "softmax"))

  return model

model = define_model()
model.summary()

define_model()

import numpy as np
  import matplotlib.pyplot as plt


  from tensorflow import keras
  from keras.utils import np_utils
  from sklearn.model_selection import train_test_split

  from keras import regularizers
  from keras import Sequential
  from keras.layers import Dense,ReLU,LeakyReLU,GlobalAveragePooling3D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation


  model = Sequential()
  model.add(Conv3D(16, kernel_size=(3, 3,3),strides=(1,2,2),input_shape=(7,120,108,3)))
  model.add(ReLU())
  
  model.add(MaxPooling3D(pool_size=(1, 2,2)))
  model.add(Conv3D(32, kernel_size=(3, 3,3),strides=(2,2,2)))
  model.add(ReLU())  
   
  model.add(Conv3D(64, kernel_size=(1, 3,3),strides=(1,2,2)))
  model.add(ReLU())
  model.add(MaxPooling3D(pool_size=(1, 2,2)))
    
   
  model.add(Flatten()) 
   
  model.add(Dense(256,kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU())  
  model.add(Dropout(0.25))
  model.add(Dense(128,kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU()) 
  
  model.add(Dense(6, activation='softmax'))
  model.summary()

optimizer = keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.5,beta_2=0.999)
model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])
EPOCHS=50 
history = model.fit(X_train,y_train,batch_size=7,epochs=EPOCHS,verbose=1,validation_split=0.2)

def plot_learning_curve(history, epochs):
  #Plot training and validation accuracy values:
  epoch_range = range(1, epochs+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.xlabel('Epochs')
  plt.ylabel('Acuuracy')
  plt.title('Accuracy curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Accuracy2.png')

  #Plot training and validation loss values :
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.axis([0,50, 0,2])
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('Loss curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Loss2.png')
EPOCHS=50
plot_learning_curve(history, EPOCHS)

model.evaluate(X_test,y_test)

print(X_test.shape)

import numpy as np
with open('/content/drive/MyDrive/dataset_har_hit/kicking.npy', 'rb') as f :
    kicking_arr = np.load(f)
with open('/content/drive/MyDrive/dataset_har_hit/pushing.npy', 'rb') as f :
    pushing_arr = np.load(f)    
with open('/content/drive/MyDrive/dataset_har_hit/vomiting.npy', 'rb') as f :
    vomiting_arr = np.load(f)
with open('/content/drive/MyDrive/dataset_har_hit/falling.npy', 'rb') as f :
    falling_arr = np.load(f)
with open('/content/drive/MyDrive/jumpUp.npy', 'rb') as f :
    wieldknife_arr = np.load(f)    
    wieldknife_arr= wieldknife_arr[:870,:,:,:,:]
with open('/content/drive/MyDrive/dataset_har_hit/normal.npy', 'rb') as f :
    noOne_arr = np.load(f)     
    noOne_arr= noOne_arr[:870,:,:,:,:]

wieldknife_arr= wieldknife_arr[:870,:,:,:,:]

print( noOne_arr.shape)

!cp "/content/y_train.npy" -r "/content/drive/MyDrive/dataset_har/"

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
#load train and test data 
with open('/content/drive/MyDrive/dataset_har/y_train.npy', 'rb') as f :
  y_train = np.load(f)
with open('/content/drive/MyDrive/dataset_har/X_test.npy', 'rb') as f :
  X_test = np.load(f)
with open('/content/drive/MyDrive/dataset_har/y_test.npy', 'rb') as f :
  y_test = np.load(f)
with open('/content/drive/MyDrive/dataset_har/X_train.npy', 'rb') as f :
  X_train = np.load(f)

import numpy as np 

  import matplotlib.pyplot as plt
  
  from tensorflow import keras
  from keras.utils import np_utils
  from sklearn.model_selection import train_test_split

  from keras import regularizers
  from keras import Sequential
  from keras.layers import Dense,ReLU,LeakyReLU,GlobalAveragePooling3D, AveragePooling3D,Conv3D,Activation, BatchNormalization, Flatten, MaxPooling3D, Dropout, Activation


  model = Sequential()
  model.add(Conv3D(16, kernel_size=(3, 3,3),strides=(1,2,2),input_shape=(7,120,108,3)))
  model.add(ReLU())
  model.add(Dropout(0.15))
  model.add(Conv3D(32, kernel_size=(3, 3,3),strides=(2,2,2)))
  model.add(ReLU())
  model.add(MaxPooling3D(pool_size=(1, 2,2))) 
  
  model.add(Conv3D(64, kernel_size=(1, 3,3),strides=(1,2,2)))
  model.add(ReLU())
  model.add(Dropout(0.15))
  model.add(Conv3D(128, kernel_size=(1, 3,3),strides=(1,2,2)))
  model.add(ReLU())  
  model.add(MaxPooling3D(pool_size=(1, 1,1))) 

  model.add(Flatten()) 
  model.add(Dense(256, kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU())
  model.add(Dropout(0.3))
  model.add(Dense(128, kernel_regularizer=regularizers.l1(0.001)))
  model.add(ReLU())
  model.add(Dense(6, activation='softmax'))
  model.summary()

optimizer = keras.optimizers.Adam(learning_rate=0.001,beta_1=0.5,beta_2=0.999)
model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])
history = model.fit(X_train,y_train,batch_size=7,epochs=70,verbose=1,validation_split=0.2)

def plot_learning_curve(history, epochs):
  #Plot training and validation accuracy values:
  epoch_range = range(1, epochs+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.xlabel('Epochs')
  plt.ylabel('Acuuracy')
  plt.title('Accuracy curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Accuracy2.png')

  #Plot training and validation loss values :
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.axis([0,70, 0,2])
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('Loss curve')
  plt.legend(['Train','Val'],loc = 'upper left')
  plt.show()
  #plt.savefig('/content/drive/My Drive/Loss2.png')
plot_learning_curve(history, 70)
model.evaluate(X_test,y_test)
print(X_test.shape)

model.save("goodlossaccuracybadgraph.h5")

!cp "/content/goodlossaccuracybadgraph.h5" -r "/content/drive/MyDrive/"

optimizer = keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.5,beta_2=0.999)
model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])
history = model.fit(X_train,y_train,batch_size=7,epochs=50,verbose=1,validation_split=0.2)



import cv2
import os
from google.colab.patches import cv2_imshow
import numpy as np
def frame_extraction(path,activite):
  
  nombreFrame=7
  kicking=[]
  listing_videos = os.listdir(path)
  cpt=0 
  for vid in listing_videos: 
    videoFile = path+'/'+vid
    cpt=cpt+1
    print(videoFile)
    videoCapture = cv2.VideoCapture(videoFile)
    fps = videoCapture.get(cv2.CAP_PROP_FPS)
    frame_count=int (videoCapture.get(cv2.CAP_PROP_FRAME_COUNT))
    duration=frame_count/fps
    seconde=duration%60 
    fram=frame_count//nombreFrame #division entiere 
    listofFrames=[]
    for i in range(nombreFrame):
      videoCapture.set(1,i*fram)
      success, frame = videoCapture.read()
      scale_percent = 10 # percent of original size
      width = 144
      height = 144
      dim = (width, height)
      resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)
      img = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
      img=resized/255
      listofFrames.append(img)
    if cpt==2 : break
    kicking.append(listofFrames)
  print(cpt) 
  kicking_arr = np.array(kicking)
  print(kicking_arr.shape)
  with open(activite+'.npy', 'wb') as f:
    np.save(f, kicking_arr)

path='/content/drive/MyDrive/dataset_har/abnormal/kicking'
activite='vomi1'
frame_extraction(path,activite)

import numpy as np 
with open("/content/vomi1.npy","rb") as f:
  push=np.load(f)
print(push.shape)

import matplotlib.pyplot as plt
img4=push[0,5,:,:,:]
plt.imshow(img4)

import matplotlib.pyplot as plt
img4=push[0,3,:,:,:]
plt.imshow(img4)

import matplotlib.pyplot as plt
img4=push[0,3,:,:,:]
plt.imshow(img4)

import matplotlib.pyplot as plt
img4=push[0,3,:,:,:]
plt.imshow(img4)

import cv2
import os
from google.colab.patches import cv2_imshow
import numpy as np
def frame_extraction(path,activite):
  
  nombreFrame=7
  kicking=[]
  listing_videos = os.listdir(path)
  cpt=0 
  for vid in listing_videos: 
    videoFile = path+'/'+vid
    cpt=cpt+1 
    videoCapture = cv2.VideoCapture(videoFile)
    fps = videoCapture.get(cv2.CAP_PROP_FPS)
    frame_count=int (videoCapture.get(cv2.CAP_PROP_FRAME_COUNT))
    duration=frame_count/fps
    seconde=duration%60 
    fram=frame_count//nombreFrame #division entiere 
    listofFrames=[]
    for i in range(nombreFrame):
      videoCapture.set(1,i*fram)
      success, frame = videoCapture.read()
      scale_percent = 10 # percent of original size
      width = 108
      height = 120
      dim = (width, height)
      resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)
      img = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
      img=resized/255
      listofFrames.append(img)
    if cpt==955 : break
    kicking.append(listofFrames)
  print(cpt) 
  kicking_arr = np.array(kicking)
  print(kicking_arr.shape)
  with open(activite+'.npy', 'wb') as f:
    np.save(f, kicking_arr)

path='/content/drive/MyDrive/abnormalaLL/wield-knife'
activite='wieldKnife'
#stand up,sit down
frame_extraction(path,activite)

!cp "/content/wieldKnife.npy" -r "/content/drive/MyDrive/"